{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Scikit-Learn Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Copilot Prompt: \n",
    "#### Provide examples to demonstrate each concept on this list to someone who is an absolute beginner in coding. I want step-by-step explanations. \n",
    "1. Working with Datasets (Focus of Part 2 of Course Lab Book)\n",
    "2. Data Preprocessing (Focus of Part 3 of Course Lab Book)\n",
    "3. Splitting Data (Focus of Part 3 of Course Lab Book)\n",
    "4. Choosing and Training a Model (Focus of Part 3 of Course Lab Book)\n",
    "5. Evaluating Model Performance (Focus of Part 3 of Course Lab Book)\n",
    "6. Improving Model Performance (Optional)\n",
    "7. Saving and Loading Models (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompts given after this response include:\n",
    "1. Can you explain data preprocessing more?\n",
    "2. What is hyperparameter tuning?\n",
    "3. How do I visualize model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Purpose of these exercises is to gain a good introduction and understanding of the Scikit-Learn Python Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Testing the Working with Datasets code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width        class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "column_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]\n",
    "iris = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(iris.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Outcome:\n",
    "- Understanding how to load and explore datasets\n",
    "- How to identify different types of data\n",
    "- Perform Basic data operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Testing the Data Preprocessing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "class           0\n",
      "dtype: int64\n",
      "   sepal_length  sepal_width  petal_length  petal_width  class\n",
      "0     -0.900681     1.032057     -1.341272    -1.312977      0\n",
      "1     -1.143017    -0.124958     -1.341272    -1.312977      0\n",
      "2     -1.385353     0.337848     -1.398138    -1.312977      0\n",
      "3     -1.506521     0.106445     -1.284407    -1.312977      0\n",
      "4     -1.021849     1.263460     -1.341272    -1.312977      0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(iris.isnull().sum())\n",
    "\n",
    "# Encode categorical variables (if any)\n",
    "# In this case, 'class' is a categorical variable\n",
    "iris['class'] = iris['class'].astype('category').cat.codes\n",
    "\n",
    "# Scale numerical features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']] = scaler.fit_transform(iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\n",
    "\n",
    "# Display the first few rows of the preprocessed dataset\n",
    "print(iris.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning Outcome\n",
    "- Understanding how to scale\n",
    "- Learned different techniques for cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Testing the Splitting Data Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (30, 4) (120,) (30,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = iris.drop('class', axis=1)\n",
    "y = iris['class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning Outcome\n",
    "- Understanding how to split data and how to present it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing the Choosing and Training a Model Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': None, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Display the model's parameters\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning Outcome\n",
    "- Learn how ti initialize and train a model using sklearn\n",
    "- Understanding how to display model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing the Evaluating Model Performance Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning Outcome\n",
    "- Understanding how evaluating a models performance can help us understand how well it generalizes to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Testing the Improving Model Performance Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Testing the Saving and Loading Models code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Save the model to a file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(\u001b[43mbest_model\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the model from the file\u001b[39;00m\n\u001b[1;32m      7\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "# Load the model from the file\n",
    "loaded_model = joblib.load('best_model.pkl')\n",
    "\n",
    "# Verify the loaded model's performance\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
    "print(f\"Loaded Model Accuracy: {accuracy_loaded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code came up with the NameError. I then asked CoPilot what was wrong with the code and to fix it. Initial response did not change anything. I then sent in the error message and this is the updated response:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the variable best_model is not defined in your code. This usually happens if the hyperparameter tuning step was skipped or if the variable was not assigned correctly. Let's ensure that best_model is properly defined before saving it.\n",
    "\n",
    "Here's a complete example that includes hyperparameter tuning and saving/loading the model:\n",
    "\n",
    "Step-by-Step Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "column_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]\n",
    "iris = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Preprocess the data\n",
    "iris['class'] = iris['class'].astype('category').cat.codes\n",
    "scaler = StandardScaler()\n",
    "iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']] = scaler.fit_transform(iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = iris.drop('class', axis=1)\n",
    "y = iris['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "# Load the model from the file\n",
    "loaded_model = joblib.load('best_model.pkl')\n",
    "\n",
    "# Verify the loaded model's performance\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
    "print(f\"Loaded Model Accuracy: {accuracy_loaded}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
